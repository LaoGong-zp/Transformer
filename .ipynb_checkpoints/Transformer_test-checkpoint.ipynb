{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:10:30.865478Z",
     "start_time": "2021-09-24T07:10:25.779749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2.1.0\n",
      "sys.version_info(major=3, minor=7, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.2\n",
      "numpy 1.17.0\n",
      "pandas 1.1.3\n",
      "sklearn 0.23.2\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# 设置gpu内存自增长\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、加载训练时保存的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:10:36.841796Z",
     "start_time": "2021-09-24T07:10:35.826866Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载训练时保存的 tokenizer\n",
    "import tensorflow_datasets as tfds\n",
    "# 如果是TensorFlow2.0，请将下面的\"deprecatrd\"换成\"features\"\n",
    "en_tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file('./tokenizer/en_tokenizer_new')\n",
    "pt_tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file('./tokenizer/en_tokenizer_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:10:41.103658Z",
     "start_time": "2021-09-24T07:10:41.038598Z"
    }
   },
   "outputs": [],
   "source": [
    "def positional_encoding(max_len, d_model):\n",
    "    pos = np.arange(max_len,dtype=float)[:,np.newaxis]\n",
    "    dim = np.arange(d_model,dtype=float)[np.newaxis,:]\n",
    "    matrix = np.multiply(pos, 1 / np.power(10000,2*(dim//2)/np.float32(d_model)))\n",
    "    matrix[:,::2] = np.sin(matrix[:,::2])\n",
    "    matrix[:, 1::2] = np.cos(matrix[:, 1::2])\n",
    "    pos_encoding = np.expand_dims(matrix, 0)\n",
    "    pos_encoding = tf.cast(pos_encoding,tf.float32)\n",
    "    return pos_encoding\n",
    "\n",
    "def scaled_pot_product_attention(Q,K,V,mask=None):\n",
    "    QK = tf.matmul(Q,K,transpose_b=True) # shape:(batch_size, heads_num, seq_len, seq_len)\n",
    "    dk = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "    scaled_attention_logits = QK / tf.math.sqrt(dk) # shape:(batch_size, heads_num, seq_len, seq_len)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += tf.multiply(mask,-1e9) # shape:(batch_size, heads_num, seq_len, seq_len)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # shape:(batch_size, heads_num, seq_len, seq_len)\n",
    "\n",
    "    attention_output = tf.matmul(attention_weights, V)  # shape:(batch_size, heads_num, seq_len, depth)\n",
    "    return attention_output, attention_weights\n",
    "\n",
    "\n",
    "def FeedForward(dff, d_model):\n",
    "    return tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(units=dff, activation='relu'),\n",
    "                tf.keras.layers.Dense(d_model),\n",
    "            ])\n",
    "\n",
    "def create_padding_mask(input_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(input_data,0),tf.float32)\n",
    "    padding_mask = padding_mask[:,tf.newaxis,tf.newaxis,:]\n",
    "    return padding_mask\n",
    "\n",
    "def create_look_ahead_mask(input_data):\n",
    "    '''\n",
    "    :param input_data: shape:(batch_size, input_seq_len)  input_seq_len包含start跟end\n",
    "    :return:\n",
    "    '''\n",
    "    seq_len = tf.shape(input_data)[1]\n",
    "    return 1-tf.linalg.band_part(tf.ones((seq_len,seq_len)),-1,0)\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, heads_num):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.WQ = tf.keras.layers.Dense(units=d_model)\n",
    "        self.WK = tf.keras.layers.Dense(units=d_model)\n",
    "        self.WV = tf.keras.layers.Dense(units=d_model)\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        self.depth = d_model // heads_num\n",
    "        self.heads_num = heads_num\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def split_head(self, input):\n",
    "        '''\n",
    "        :param input: shape: (batch_size, seq_len, d_model)\n",
    "        :return: shape: (batch_size, heads_num, seq_len, depth)\n",
    "        '''\n",
    "        batch_size = tf.shape(input)[0]\n",
    "        seq_len = tf.shape(input)[1]\n",
    "        input = tf.reshape(input, (batch_size, seq_len, self.heads_num, self.depth)) # shape:(batch_size, seq_len, heads_num, depth)\n",
    "        return tf.transpose(input,perm=[0,2,1,3]) # shape:(batch_size, heads_num, seq_len, depth)\n",
    "\n",
    "    def call(self,q,k,v,padding_mask):\n",
    "        '''\n",
    "        :param q:  shape:(batch_size, input_seq_len, d_model)\n",
    "        :param k:  shape:(batch_size, input_seq_len, d_model)\n",
    "        :param v:  shape:(batch_size, input_seq_len, d_model)\n",
    "        :return:   shape:(batch_size, input_seq_len, d_model)    shape:(batch_size, heads_num, seq_len, seq_len)\n",
    "        '''\n",
    "        Q = self.WQ(q) # shape:(batch_size, seq_len, d_model)\n",
    "        K = self.WK(k) # shape:(batch_size, seq_len, d_model)\n",
    "        V = self.WV(v) # shape:(batch_size, seq_len, d_model)\n",
    "\n",
    "        Q = self.split_head(Q) # shape:(batch_size, heads_num, seq_len, depth)\n",
    "        K = self.split_head(K) # shape:(batch_size, heads_num, seq_len, depth)\n",
    "        V = self.split_head(V) # shape:(batch_size, heads_num, seq_len, depth)\n",
    "\n",
    "        attention_output, attention_weights = scaled_pot_product_attention(Q,K,V,padding_mask) # shape:(batch_size, heads_num, seq_len, depth)\n",
    "        attention_output = tf.transpose(attention_output, perm=[0,2,1,3]) # shape:(batch_size, seq_len, heads_num, depth)\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        seq_len = tf.shape(q)[1]\n",
    "        concat_attention = tf.reshape(attention_output, (batch_size, seq_len, self.d_model)) # shape:(batch_size, input_seq_len, d_model)\n",
    "        output = self.dense(concat_attention) # shape:(batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "def positional_encoding(max_len, d_model):\n",
    "    pos = np.arange(max_len,dtype=float)[:,np.newaxis]\n",
    "    dim = np.arange(d_model,dtype=float)[np.newaxis,:]\n",
    "    matrix = np.multiply(pos, 1 / np.power(10000,2*(dim//2)/np.float32(d_model)))\n",
    "    matrix[:,::2] = np.sin(matrix[:,::2])\n",
    "    matrix[:, 1::2] = np.cos(matrix[:, 1::2])\n",
    "    pos_encoding = np.expand_dims(matrix, 0)\n",
    "    pos_encoding = tf.cast(pos_encoding,tf.float32)\n",
    "    return pos_encoding\n",
    "\n",
    "# *******************************************************************************\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, heads_num, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, heads_num)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.mha2 = MultiHeadAttention(d_model, heads_num)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.ffn = FeedForward(dff, d_model)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        self.layer_norm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, input, encoder_ouput, encoder_decoder_padding_mask, masked_attention_mask, training=False):\n",
    "        '''\n",
    "        :param input:          shape:  (batch_size, target_seq_len, d_model)\n",
    "        :param encoder_ouput:  shape:  (batch_size, input_seq_len, d_model)\n",
    "        :param encoder_decoder_padding_mask:\n",
    "        :param masked_attention_mask:\n",
    "        :return:\n",
    "        '''\n",
    "        q = input\n",
    "        k = input\n",
    "        v = input\n",
    "        attn1_output, attn1_weights = self.mha1(q, k, v, masked_attention_mask)  # shape:(batch_size, target_seq_len, d_model)\n",
    "        attn1_output = self.dropout1(attn1_output,training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "        output1 = self.layer_norm1(input + attn1_output) # shape:(batch_size, target_seq_len, d_model)\n",
    "\n",
    "        q = output1        # shape: (batch_size, target_seq_len, d_model)\n",
    "        k = encoder_ouput  # shape: (batch_size, input_seq_len, d_model)\n",
    "        v = encoder_ouput  # shape: (batch_size, input_seq_len, d_model)\n",
    "        attn2_output, attn2_weights = self.mha2(q, k, v, encoder_decoder_padding_mask)  # shape:(batch_size, target_seq_len, d_model)\n",
    "        attn2_output = self.dropout2(attn2_output,training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "        output2 = self.layer_norm2(output1 + attn2_output) # shape:(batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(output2)  # shape:(batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)  # shape:(batch_size, target_seq_len, d_model)\n",
    "        output3 = self.layer_norm3(output2 + ffn_output)  # shape:(batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return output3\n",
    "\n",
    "class DecoderModel(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_vocab_size, d_model, max_len, heads_num, dff, layers_num, rate=0.1):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.decoder_layers = [DecoderLayer(d_model, heads_num, dff, rate) for _ in range(layers_num)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, input, encoder_ouput, encoder_decoder_padding_mask, training=False):\n",
    "        '''\n",
    "        :param input:         shape:(batch_size, target_seq_len)  target_seq_len只包含start\n",
    "        :param encoder_ouput: shape:(batch_size, input_seq_len, d_model)\n",
    "        :param training:\n",
    "        :return:\n",
    "        '''\n",
    "        decoder_padding_mask = create_padding_mask(input)\n",
    "        look_ahead_mask = create_look_ahead_mask(input)\n",
    "        masked_attention_mask = tf.maximum(decoder_padding_mask, look_ahead_mask)\n",
    "\n",
    "        input_embedding = self.embedding(input) # shape:(batch_size, target_seq_len, d_model)\n",
    "        input_embedding = input_embedding * tf.math.sqrt(tf.cast(self.d_model,tf.float32)) # shape:(batch_size, target_seq_len, d_model)\n",
    "        pos_encoding = positional_encoding(self.max_len, self.d_model)  # shape: (1, max_len, d_model)\n",
    "\n",
    "        input_seq_len = tf.shape(input)[1]\n",
    "        input_pos_embedding = input_embedding + pos_encoding[:,:input_seq_len,:] # shape:(batch_size, input_seq_len, d_model)\n",
    "        x = self.dropout(input_pos_embedding, training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            x = decoder_layer(x, encoder_ouput, encoder_decoder_padding_mask, masked_attention_mask, training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "        decoder_ouput = x\n",
    "        return decoder_ouput # shape:(batch_size, input_seq_len, d_model)\n",
    "# *******************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *******************************************************************************\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, heads_num, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, heads_num)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn = FeedForward(dff, d_model)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, input, padding_mask, training=False):\n",
    "        '''\n",
    "        :param input:  shape: (batch_size, input_seq_len, d_model)\n",
    "        :param training:\n",
    "        :return:\n",
    "        '''\n",
    "        q = input\n",
    "        k = input\n",
    "        v = input\n",
    "        attn_output, attn_weights = self.mha(q,k,v,padding_mask) # shape:(batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output,training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "        output1 = self.layer_norm1(input + attn_output) # shape:(batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(output1) # shape:(batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output,training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "        output2 = self.layer_norm2(output1 + ffn_output) # shape:(batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return output2 # shape:(batch_size, input_seq_len, d_model)\n",
    "\n",
    "class EncoderModel(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, d_model, max_len, heads_num, dff, layers_num, rate=0.1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.encoder_layers = [EncoderLayer(d_model, heads_num, dff, rate) for _ in range(layers_num)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, input, training=False):\n",
    "        '''\n",
    "        :param input:  shape:(batch_size, input_seq_len)  input_seq_len包含start跟end\n",
    "        :param training:\n",
    "        :return:\n",
    "        '''\n",
    "        padding_mask = create_padding_mask(input)\n",
    "\n",
    "        input_embedding = self.embedding(input) # shape:(batch_size, input_seq_len, d_model)\n",
    "        input_embedding = input_embedding * tf.math.sqrt(tf.cast(self.d_model,tf.float32)) # shape:(batch_size, input_seq_len, d_model)\n",
    "        pos_encoding = positional_encoding(self.max_len, self.d_model)  # shape: (1, max_len, d_model)\n",
    "\n",
    "        input_seq_len = tf.shape(input)[1]\n",
    "        input_pos_embedding = input_embedding + pos_encoding[:,:input_seq_len,:] # shape:(batch_size, input_seq_len, d_model)\n",
    "        x = self.dropout(input_pos_embedding, training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x, padding_mask, training=training) # shape:(batch_size, input_seq_len, d_model)\n",
    "        encoder_ouput = x\n",
    "        return encoder_ouput, padding_mask # shape:(batch_size, input_seq_len, d_model)\n",
    "\n",
    "# *******************************************************************************\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, input_vocab_size, target_vocab_size, d_model, max_len, heads_num, dff, layers_num, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.EncoderModel = EncoderModel(input_vocab_size, d_model, max_len, heads_num, dff, layers_num)\n",
    "        self.DecoderModel = DecoderModel(target_vocab_size, d_model, max_len, heads_num, dff, layers_num)\n",
    "        self.linear = tf.keras.layers.Dense(units=target_vocab_size)\n",
    "\n",
    "\n",
    "    def call(self, encoder_input, decoder_input, training=False):\n",
    "        '''\n",
    "        :param encoder_input:  shape:(batch_size, input_seq_len)  input_seq_len包含start跟end\n",
    "        :param decoder_input:  shape:(batch_size, target_seq_len)  target_seq_len只包含end\n",
    "        :param training:\n",
    "        :return:\n",
    "        '''\n",
    "        encoder_ouput, encoder_decoder_padding_mask = self.EncoderModel(encoder_input, training=training)\n",
    "        decoder_ouput = self.DecoderModel(decoder_input, encoder_ouput, encoder_decoder_padding_mask, training=training)\n",
    "        predictions = self.linear(decoder_ouput) # shape:(batch_size, input_seq_len, d_model)\n",
    "        predictions = tf.nn.softmax(predictions, axis=-1)\n",
    "        return predictions # shape: (batch_size, target_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3、模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:10:54.815684Z",
     "start_time": "2021-09-24T07:10:54.746578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "d_model = 128\n",
    "max_len = 40\n",
    "heads_num = 8\n",
    "dff = 512\n",
    "layers_num = 4\n",
    "transformer = Transformer(input_vocab_size, target_vocab_size, d_model, max_len, heads_num, dff, layers_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4、加载训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:10:59.462859Z",
     "start_time": "2021-09-24T07:10:58.749211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2aa27a7a0c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(model=transformer)\n",
    "checkpoint.restore(tf.train.latest_checkpoint('./checkpoint'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5、预测与使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:13:46.576921Z",
     "start_time": "2021-09-24T07:13:46.567911Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalute(inp_sentence, model):\n",
    "    input_id_sentence = [pt_tokenizer.vocab_size]+pt_tokenizer.encode(inp_sentence)+ [pt_tokenizer.vocab_size+1]\n",
    "    encoder_input =tf.expand_dims(input_id_sentence,0) # (1,input_sentence_length)\n",
    "    decoder_input = tf.expand_dims([en_tokenizer.vocab_size],0) # (1,1)\n",
    "    for i in range(max_len):\n",
    "        predictions = model(encoder_input, decoder_input, training=False)\n",
    "        predictions = predictions[:,-1,:] # 单步\n",
    "        predictions_id = tf.cast(tf.argmax(predictions,axis=-1),tf.int32) #预测概率最大的值\n",
    "        if tf.equal(predictions_id,en_tokenizer.vocab_size+1):\n",
    "            return tf.squeeze(decoder_input,axis=0)\n",
    "        \n",
    "        decoder_input = tf.concat([decoder_input,[predictions_id]],\n",
    "                                  axis=-1)\n",
    "    return tf.squeeze(decoder_input,axis=0)\n",
    "\n",
    "\n",
    "def translate(input_sentence, model):\n",
    "    result = evalute(input_sentence, model)\n",
    "    predicted_sentence = en_tokenizer.decode([i for i in result if i < en_tokenizer.vocab_size])\n",
    "    print(\"Input: {}\".format(input_sentence))\n",
    "    print(\"Predicted translation: {}\".format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6、使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:13:49.530601Z",
     "start_time": "2021-09-24T07:13:49.090201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: obrigado .\n",
      "Predicted translation: thank you .\n"
     ]
    }
   ],
   "source": [
    "# 正式使用\n",
    "input_sentence = 'obrigado .'\n",
    "translate(input_sentence.lower(),transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T03:03:30.706490Z",
     "start_time": "2021-09-17T03:03:29.947799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: eu acredito que posso voar .\n",
      "Predicted translation: i believe i can fly .\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# 正式使用\n",
    "input_sentence = 'Eu acredito que posso voar .'\n",
    "translate(input_sentence.lower(),transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T11:34:42.431162Z",
     "start_time": "2021-09-24T11:34:41.609245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ele é nosso marido .\n",
      "Predicted translation: and he 's our husband .\n"
     ]
    }
   ],
   "source": [
    "# 正式使用\n",
    "input_sentence = 'Ele é Nosso marido .'\n",
    "translate(input_sentence.lower(),transformer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF2.1] *",
   "language": "python",
   "name": "conda-env-TF2.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
